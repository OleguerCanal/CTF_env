behaviors:
  CTFAgentBehavior:
    trainer_type: ppo
    hyperparameters:
      batch_size: 200  # Num experiences in each iteration of gradient descend
      buffer_size: 10000  # Num experiences to be filled before updating weights
      learning_rate: 3.0e-4
      beta: 5.0e-4  # Weight of the entropy: If entropy drops too quickly, increase beta
      epsilon: 0.2  # How rapidly can the policy change
      lambd: 0.95
      num_epoch: 3
      learning_rate_schedule: linear
    network_settings:
      normalize: false
      hidden_units: 250
      num_layers: 2
      memory:
        memory_size: 200
        sequence_length: 200
    reward_signals:
      extrinsic:
        gamma: 0.99
        strength: 1.0
      # curiosity:
      #   strength: 0.02
      #   gamma: 0.99
      #   encoding_size: 256
      #   learning_rate: 3.0e-4
    max_steps: 30e6 # Steps collected in one training per-behavior
    time_horizon: 2500 # Steps collected per-agent added to buffer (if shorter than episode remaining value estimate is used)
    summary_freq: 10000


environment_parameters:
  # Reward
  finishReward: 1.0
  notFinishedReward: -0.25
  timeReward: -0.0005  # Doing nothing leads to reward -1
  collectableReward: 0.0
  enemyCloseReward: 0.0
  deathByEnemyReward: -2.0

  mapRepetitions: 10  # Number of times to repeat the same map
  enemySpeed: 0.015  # Number of times to repeat the same map


  # Enemies velocity
  levelDifficulty:
    curriculum:
      - name: Lesson0
        completion_criteria:
          measure: reward
          behavior: CTFAgentBehavior
          signal_smoothing: true
          min_lesson_length: 500
          threshold: 0.4
        value: 0.0
      - name: Lesson1
        completion_criteria:
          measure: reward
          behavior: CTFAgentBehavior
          signal_smoothing: true
          min_lesson_length: 500
          threshold: 0.4
          require_reset: true
        value: 1.0
      - name: Lesson2
        completion_criteria:
          measure: reward
          behavior: CTFAgentBehavior
          signal_smoothing: true
          min_lesson_length: 500
          threshold: 0.4
          require_reset: true
        value: 2.0
      - name: Lesson3
        completion_criteria:
          measure: reward
          behavior: CTFAgentBehavior
          signal_smoothing: true
          min_lesson_length: 500
          threshold: 0.4
          require_reset: true
        value: 3.0
      - name: Lesson4
        completion_criteria:
          measure: reward
          behavior: CTFAgentBehavior
          signal_smoothing: true
          min_lesson_length: 500
          threshold: 0.4
          require_reset: true
        value: 4.0
      - name: Lesson5
        completion_criteria:
          measure: reward
          behavior: CTFAgentBehavior
          signal_smoothing: true
          min_lesson_length: 500
          threshold: 0.4
          require_reset: true
        value: 5.0
      - name: Lesson6
        completion_criteria:
          measure: reward
          behavior: CTFAgentBehavior
          signal_smoothing: true
          min_lesson_length: 500
          threshold: 0.4
          require_reset: true
        value: 6.0
      - name: Lesson7
        completion_criteria:
          measure: reward
          behavior: CTFAgentBehavior
          signal_smoothing: true
          min_lesson_length: 500
          threshold: 0.4
          require_reset: true
        value: 7.0
      - name: Lesson8
        completion_criteria:
          measure: reward
          behavior: CTFAgentBehavior
          signal_smoothing: true
          min_lesson_length: 500
          threshold: 0.4
          require_reset: true
        value: 8.0
      - name: Lesson9
        completion_criteria:
          measure: reward
          behavior: CTFAgentBehavior
          signal_smoothing: true
          min_lesson_length: 500
          threshold: 0.4
          require_reset: true
        value: 9.0
      - name: Lesson10
        value: 10.0